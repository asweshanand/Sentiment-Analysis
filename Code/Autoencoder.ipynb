{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import json\n","import openpyxl\n","import pandas as pd\n","from collections import Counter\n","import string\n","import re\n","import csv\n","from gensim.models import LdaModel\n","from sklearn.preprocessing import normalize\n","import numpy as np\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from torch import nn\n","import torch\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from transformers import RobertaTokenizer, RobertaModel\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","from torchtext.data.utils import get_tokenizer\n","import torch.optim as optim\n","from nltk.stem import WordNetLemmatizer\n","from nltk import pos_tag\n","\n","\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","\n","lemmatizer = WordNetLemmatizer()"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["'some of the figures and illustrations are deficient in e book format'"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["raw_data=[]\n","sentiment=[]\n","file_path = '../Data/Amazon Review Data.xlsx'  \n","workbook = openpyxl.load_workbook(file_path)\n","sheet = workbook.active\n","\n","for row in sheet.iter_rows(values_only=True):\n","    raw_data.append(row[1])\n","    sentiment.append(row[2])\n","\n","workbook.close()\n","raw_data=raw_data[1:]\n","sentiment=sentiment[1:]\n","raw_data[0]"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[],"source":["# Clean data for topic modelling\n","def pre_process_noun(sentence):\n","    res=word_tokenize(sentence)\n","    res=pos_tag(res)\n","    res=[lemmatizer.lemmatize(word.lower()) for word,tag in res if tag.startswith('NN') and word.isalpha() and word.isascii()]\n","   \n","    return res\n","# Clean data for sentiment analysis\n","def pre_process_adj(sentence):\n","    res=word_tokenize(sentence)\n","    res=pos_tag(res)\n","    res=[lemmatizer.lemmatize(word.lower()) for word,tag in res if tag.startswith('JJ') and word.isalpha() and word.isascii()]\n","   \n","    return res"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['figure', 'illustration', 'book', 'format'] 1235\n"]}],"source":["data_list=[]\n","for i in raw_data:\n","    data_list.append(pre_process_noun(i))\n","print(data_list[0],len(data_list))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","model = RobertaModel.from_pretrained('roberta-base')\n","\n","# Function to get embeddings from RoBERTa\n","def get_roberta_embedding(phrase):\n","    inputs = tokenizer(phrase, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","    # Get the CLS token embedding\n","    cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n","    return cls_embedding"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[{"data":{"text/plain":["1235"]},"execution_count":62,"metadata":{},"output_type":"execute_result"}],"source":["len(data_list)"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[],"source":["flat_list = [word for sublist in data_list for word in sublist]"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[{"data":{"text/plain":["15374"]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["len(flat_list)"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[],"source":["distinct_word=list(set(flat_list))"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[{"data":{"text/plain":["1996"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["len(distinct_word)"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[],"source":["# Put roberta_embedding in a dictionary\n","robert_dict = {}\n","for word in distinct_word:\n","    robert_dict[word]=get_roberta_embedding(word)"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['deficient', 'e'] 1235\n"]}],"source":["data_list_adj=[]\n","for i in raw_data:\n","    data_list_adj.append(pre_process_adj(i))\n","print(data_list_adj[0],len(data_list_adj))"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[],"source":["embedding_dim = 768"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(1198, 768)\n","1198\n","1198\n"]}],"source":["from sklearn.preprocessing import normalize\n","import numpy as np\n","embed=[]\n","sen_avg_emd=[]\n","data_list_adj_final=[]\n","sentiment_final=[]\n","# Find average embedding for each sentence\n","for idx,i in enumerate(data_list):\n","    if i:\n","        new=np.array([robert_dict[ii] for ii in i ])\n","        embed.append(np.mean(new,axis=0))\n","        data_list_adj_final.append(data_list_adj[idx])\n","        sentiment_final.append(sentiment[idx])\n","\n","embed=np.array(embed)\n","print(embed.shape)\n","sen_avg_emd=embed\n","sen_avg_emd.shape\n","print(len(data_list_adj_final))\n","print(len(sentiment_final))\n"]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[{"data":{"text/plain":["(5, 768)"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.cluster import KMeans\n","import numpy as np\n","output_dim = 5\n","kmeans = KMeans(n_clusters=output_dim, random_state=0).fit(sen_avg_emd)\n","kmeans.labels_\n","\n","topic_embedding_init=kmeans.cluster_centers_\n","topic_embedding_init.shape"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(768,)\n","Closest words:\n","song, tale, core, buck, style, leader, pocket, cause, bare, someone\n","--------------------------\n","(768,)\n","Closest words:\n","root, setting, leader, taker, pointer, binding, depth, gre, absolute, dh\n","--------------------------\n","(768,)\n","Closest words:\n","book, author, pick, perfect, flame, library, text, uk, building, cloth\n","--------------------------\n","(768,)\n","Closest words:\n","song, leader, root, tale, bare, depth, shine, setting, bind, stick\n","--------------------------\n","(768,)\n","Closest words:\n","style, song, flame, perfect, book, model, buck, translation, super, piece\n","--------------------------\n"]}],"source":["\n","def find_closest_words(robert_dict, vector, top_n=10):\n","    # Find 10th closest word (topic) in embedding for topics\n","    similarities = {}\n","    for word, embedding in robert_dict.items():\n","        cosine_similarity = np.dot(vector, embedding) / (np.linalg.norm(vector) * np.linalg.norm(embedding))\n","        similarities[word] = cosine_similarity\n","    closest_words = sorted(similarities.items(), key=lambda item: item[1], reverse=True)\n","    return closest_words[:10]\n","\n","for example_vector in topic_embedding_init:\n","    print(example_vector.shape)\n","    closest_words = find_closest_words(robert_dict, example_vector,distinct_word)\n","    \n","    print(\"Closest words:\")\n","    #for word, similarity in closest_words:\n","        #print(f\"{word}: {similarity:.4f}\")\n","    print(', '.join([i[0] for i in closest_words]))\n","    print(\"--------------------------\")"]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[{"data":{"text/plain":["897"]},"execution_count":75,"metadata":{},"output_type":"execute_result"}],"source":["sen_avg_emd.shape[0]//4*3"]},{"cell_type":"code","execution_count":76,"metadata":{"cell_id":45},"outputs":[],"source":["from collections import Counter\n","\n","\n","class TorchDataset(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n"," \n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","\n","        return torch.tensor(self.data[idx],dtype=torch.float32)\n","    \n","# Batch sizes\n","batch_size = 40\n","eval_batch_size = 30\n","\n","\n","dataset = TorchDataset(sen_avg_emd[:sen_avg_emd.shape[0]//4*3])\n","loader = DataLoader(dataset, batch_size=batch_size)\n","dev_dataset = TorchDataset(sen_avg_emd[sen_avg_emd.shape[0]//4*3:])\n","dev_loader = DataLoader(dev_dataset, batch_size=eval_batch_size)\n","\n"]},{"cell_type":"code","execution_count":77,"metadata":{"cell_id":54},"outputs":[],"source":["def train(model, loader, optimizer, criterion):\n","    model.train()\n","    total_loss = 0\n","    for review in loader:\n","        optimizer.zero_grad()\n","        outputs = model(review)\n","        loss = criterion(outputs, review)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    \n","\n","def train_eval(model, loader, test_loader, optimizer, criterion):\n","    \n","    model.train()\n","    total_loss = 0\n","   \n","    for review in loader:\n","        \n","        optimizer.zero_grad()\n","        outputs = model(review)\n","        loss = criterion(outputs, review)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    \n","    a= total_loss / len(loader)\n","\n","    model.eval()\n","    results = []\n","    total_loss = 0\n","    with torch.no_grad():\n","        for review in test_loader:\n","            \n","            #print(len(evidences[0]))=5\n","            outputs = model(review)\n","            loss = criterion(outputs, review)\n","            total_loss += loss.item()\n","\n","    avg_loss = total_loss / len(test_loader)\n"," \n","    return [a, total_loss / len(test_loader)]"]},{"cell_type":"code","execution_count":78,"metadata":{"cell_id":67},"outputs":[],"source":["import torch.nn.functional as F\n","class Regre(nn.Module):\n","    \n"," \n","    def __init__(self, topic_embedding_init,embedding_dim, topic_dim):\n","        super(Regre, self).__init__()\n","        self.encoder = nn.Linear(embedding_dim , topic_dim)\n","        self.topic_dim=topic_dim\n","        # topic embedding\n","        self.topic = nn.Parameter(torch.tensor(topic_embedding_init, dtype=torch.float32))\n","\n","    def forward(self, review):\n","        \n","        #h [batch, topic_dim]\n","        # Distribution of topics\n","        h_dis=self.encoder(review)\n","        #out [batch, embedding]\n","        # projection of topic and distribution\n","        out=torch.matmul(h_dis,self.topic)/self.topic_dim**0.5\n","\n","        \n","        #self.topic [batch, embedding]\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":55},"outputs":[],"source":["\n","epoch = 100\n","lr = 0.05\n","import matplotlib.pyplot as plt \n","\n","\n","# Train\n","                        \n","# plot the train & validation loss to find the # of epochs to use\n","for i in range(1):\n","    model = Regre(topic_embedding_init=topic_embedding_init, embedding_dim=embedding_dim, topic_dim=output_dim)\n","    criterion = nn.MSELoss()\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","\n","    l1,l2=[],[]\n","    for epoch in range(epoch):\n","   \n","        [a,b]=train_eval(model, loader, dev_loader, optimizer, criterion)\n","        l1.append(a)\n","        l2.append(b)\n","    z=list(range(len(l1)))\n","    \n","      \n","    # plot lines \n","    plt.plot(z, l1, label = \"train\", linestyle=\"-\") \n","    plt.plot(z, l2, label = \"val\", linestyle=\"--\") \n","    plt.legend() \n","    plt.show()\n"]},{"cell_type":"code","execution_count":96,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Closest words:\n","dentaltown, manual, wearer, jocko, eigth, hygienist, schusterthe, professionalism, leaguer, hygientist\n","--------------------------\n","Closest words:\n","therapist, hygiene, dental, healthcare, therapy, complexity, syndrome, trainer, surgeon, university\n","--------------------------\n","Closest words:\n","texbook, purchase, guidebook, textbook, workbook, book, handbook, certificate, hardcover, packet\n","--------------------------\n","Closest words:\n","explenation, anagram, stylistically, instagram, canada, mike, simpson, lesion, barrons, preface\n","--------------------------\n","Closest words:\n","for, justice, break, change, flow, clear, action, come, cream, item\n","--------------------------\n"]}],"source":["for name, param in model.named_parameters():\n","    if name =='topic':\n","        final_topic_embedding=param\n","#final_topic_embedding_arr = final_topic_embedding.detach().cpu().numpy()\n","final_topic_embedding_arr = normalize(final_topic_embedding.detach().cpu().numpy())\n","\n","\n","for example_vector in final_topic_embedding_arr:\n","    closest_words = find_closest_words(robert_dict, example_vector,distinct_word)\n","    \n","    print(\"Closest words:\")\n","    #for word, similarity in closest_words:\n","     #   print(f\"{word}: {similarity:.4f}\")\n","    print(', '.join([i[0] for i in closest_words]))\n","    print(\"--------------------------\")"]},{"cell_type":"code","execution_count":82,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Value counts: Counter({4: 475, 1: 301, 5: 212, 2: 172, 3: 38})\n"]}],"source":["final_topic=[]\n","import numpy as np\n","def similarity(vec1, vec2):\n","\n","    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n","for review_embedding in sen_avg_emd:\n","    topic_distribution=[]\n","    for topic_embedding in topic_embedding_init:\n","        topic_distribution.append(similarity(review_embedding, topic_embedding))\n","    final_topic.append(topic_distribution.index(max(topic_distribution))+1)\n","count = Counter(final_topic)\n","\n","print(\"Value counts:\", count)"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Value counts: Counter({3: 672, 4: 521, 5: 5})\n"]}],"source":["final_topic=[]\n","import numpy as np\n","def similarity(vec1, vec2):\n","\n","    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n","for review_embedding in sen_avg_emd:\n","    topic_distribution=[]\n","    for topic_embedding in final_topic_embedding_arr:\n","        topic_distribution.append(similarity(review_embedding, topic_embedding))\n","    final_topic.append(topic_distribution.index(max(topic_distribution))+1)\n","count = Counter(final_topic)\n","\n","print(\"Value counts:\", count)\n"]},{"cell_type":"code","execution_count":85,"metadata":{},"outputs":[],"source":["posi=[]\n","neu=[]\n","nega=[]\n","for idx,i in enumerate(sentiment_final):\n","    if ''.join(i)=='negative':\n","        nega.extend(data_list_adj_final[idx])\n","    if ''.join(i)=='positive':\n","        posi.extend(data_list_adj_final[idx])\n","    if ''.join(i)=='neutral':\n","        neu.extend(data_list_adj_final[idx])\n","    "]},{"cell_type":"code","execution_count":86,"metadata":{},"outputs":[],"source":["doc3=[[],[],[]]\n","doc2=[[],[],[]]\n","senti_idx_dict={}\n","senti_idx_dict['positive']=0\n","senti_idx_dict['negative']=1\n","senti_idx_dict['neutral']=2\n","for idx,i in enumerate(final_topic):\n","    if i==3:\n","        doc3[senti_idx_dict[''.join(sentiment_final[idx])]].extend(data_list_adj_final[idx])\n","    if i==2:\n","        doc2[senti_idx_dict[''.join(sentiment_final[idx])]].extend(data_list_adj_final[idx])\n","   "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":87,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['dental', 'easy', 'orthodontic', 'more', 'useful', 'aesthetic', 'effective', 'excellent', 'medical', 'successful']\n","['pdf', 'bent', 'excited', 'extended', 'glossy', 'inguinal', 'kindle', 'minimal', 'overpriced', 'primary']\n","['dental', 'spanish', 'more', 'many', 'first', 'most', 'present', 'least', 'local', 'poor']\n"]}],"source":["import gensim\n","from gensim import corpora\n","from gensim.models import TfidfModel\n","\n","senti_doc=[posi,neu,nega]\n","\n","dictionary = corpora.Dictionary(senti_doc)\n","corpus = [dictionary.doc2bow(text) for text in senti_doc]\n","\n","tfidf = TfidfModel(corpus)\n","\n","for doc in tfidf[corpus]:\n","    tfidf_val=[[dictionary[id], freq] for id, freq in doc]\n","    sorted_data = sorted(tfidf_val, key=lambda x: x[1],reverse=True)\n","    print([i[0] for i in sorted_data[:10]])\n"]},{"cell_type":"code","execution_count":89,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['dental', 'great', 'good', 'easy', 'more', 'successful', 'orthodontic', 'useful', 'medical', 'helpful']\n","['dental', 'good', 'other', 'more', 'spanish', 'many', 'great', 'first', 'most', 'few']\n","['pdf', 'fine', 'good', 'anatomical', 'bent', 'extended', 'glossy', 'horrible', 'kindle', 'unglued']\n"]}],"source":["import gensim\n","from gensim import corpora\n","from gensim.models import TfidfModel\n","\n","doc3.extend(doc2)\n","\n","\n","dictionary = corpora.Dictionary(doc3)\n","corpus = [dictionary.doc2bow(text) for text in doc3]\n","\n","\n","tfidf = TfidfModel(corpus)\n","\n","\n","for doc in tfidf[corpus][:3]:\n","    tfidf_val=[[dictionary[id], freq] for id, freq in doc]\n","    sorted_data = sorted(tfidf_val, key=lambda x: x[1],reverse=True)\n","    print([i[0] for i in sorted_data[:10]])"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"max_cell_id":68},"nbformat":4,"nbformat_minor":2}
